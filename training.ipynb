{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481dc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Alif  0.0  0.0.1  -0.14189189189189189  -0.2972972972972973  \\\n",
      "0  Alif  0.0    0.0             -0.140940            -0.308725   \n",
      "1  Alif  0.0    0.0             -0.149660            -0.299320   \n",
      "2  Alif  0.0    0.0             -0.143836            -0.294521   \n",
      "3  Alif  0.0    0.0             -0.155405            -0.297297   \n",
      "4  Alif  0.0    0.0             -0.142857            -0.299320   \n",
      "\n",
      "   -0.16891891891891891  -0.5878378378378378  -0.14189189189189189.1  \\\n",
      "0             -0.167785            -0.597315               -0.147651   \n",
      "1             -0.170068            -0.591837               -0.142857   \n",
      "2             -0.171233            -0.582192               -0.136986   \n",
      "3             -0.175676            -0.587838               -0.148649   \n",
      "4             -0.176871            -0.591837               -0.156463   \n",
      "\n",
      "   -0.8040540540540541  -0.12162162162162163  ...  -0.0472972972972973  \\\n",
      "0            -0.805369             -0.120805  ...            -0.053691   \n",
      "1            -0.809524             -0.108844  ...            -0.047619   \n",
      "2            -0.801370             -0.109589  ...            -0.047945   \n",
      "3            -0.810811             -0.121622  ...            -0.040541   \n",
      "4            -0.809524             -0.129252  ...            -0.047619   \n",
      "\n",
      "   -0.12162162162162163.1  0.20270270270270271  -0.02027027027027027  \\\n",
      "0               -0.120805             0.201342             -0.020134   \n",
      "1               -0.122449             0.204082             -0.006803   \n",
      "2               -0.109589             0.212329              0.006849   \n",
      "3               -0.128378             0.209459             -0.027027   \n",
      "4               -0.115646             0.197279             -0.006803   \n",
      "\n",
      "   -0.11486486486486487.1  0.04054054054054054  -0.08783783783783784  \\\n",
      "0               -0.100671             0.040268             -0.080537   \n",
      "1               -0.095238             0.054422             -0.074830   \n",
      "2               -0.109589             0.068493             -0.082192   \n",
      "3               -0.121622             0.054054             -0.087838   \n",
      "4               -0.122449             0.061224             -0.095238   \n",
      "\n",
      "   0.04054054054054054.1  0.006756756756756757  0.006756756756756757.1  \n",
      "0               0.026846              0.006711               -0.006711  \n",
      "1               0.047619              0.013605                0.006803  \n",
      "2               0.061644              0.013699                0.020548  \n",
      "3               0.040541              0.020270               -0.006757  \n",
      "4               0.054422              0.006803                0.013605  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Splitting data\n",
      "Hidden layer size,trainDataAccuracy,testDataAccuracy\n",
      "Creating model\n",
      "Training....\n",
      "100, 0.9998216515070447 ,0.9985734664764622\n",
      "Model score on train data:  0.9998216515070447\n",
      "Model score on test data:  0.9985734664764622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Path to the dataset\n",
    "path = \"dataset/keypoint_meg.csv\"\n",
    "\n",
    "# Reading dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Printing 1st 5 rows of the data set to ensure file and content loaded correctly\n",
    "print( df.head() )\n",
    "\n",
    "# Checking for empty parameters in records\n",
    "df.isna().any()\n",
    "\n",
    "# Separating column numbers from 1 to the last column as input for the MLP classifier\n",
    "X = df.iloc[:, 1:]\n",
    "\n",
    "#Separating 1st column as the output\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "# Splitting data in to training and testing\n",
    "print(\"Splitting data\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "print(\"Hidden layer size,trainDataAccuracy,testDataAccuracy\")\n",
    "\n",
    "# Making the MLP model\n",
    "print(\"Creating model\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "activation='logistic', solver='adam',\n",
    "learning_rate='constant', learning_rate_init=0.001,\n",
    "max_iter=5000)\n",
    "\n",
    "# Training the model on dataset\n",
    "print(\"Training....\")\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "#print(\"Training.... Done\")\n",
    "\n",
    "#print(\"Predicting\")\n",
    "# Testing the model using test data\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "# Printing model accuraccy on training dataset and testing dataset\n",
    "print(str(100)+\",\",str(model.score(X_train, y_train)),str(\",\")+str(model.score(X_test, y_test)))\n",
    "print(\"Model score on train data: \",model.score(X_train, y_train))\n",
    "print(\"Model score on test data: \",model.score(X_test, y_test))\n",
    "\n",
    "# Filename/Path for the model to be saved\n",
    "filename = 'models/finalized_model_meg_keypoint.sav'\n",
    "\n",
    "# Saving model\n",
    "pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44de9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sign  L1x  L1y       L2x       L2y       L3x       L3y       L4x       L4y  \\\n",
      "0  Alif    0    0 -0.091241 -0.262774 -0.109489 -0.558394 -0.127737 -0.784672   \n",
      "1  Alif    0    0 -0.108392 -0.269231 -0.132867 -0.562937 -0.139860 -0.790210   \n",
      "2  Alif    0    0 -0.120000 -0.250909 -0.152727 -0.552727 -0.170909 -0.785455   \n",
      "3  Alif    0    0 -0.118056 -0.250000 -0.142361 -0.555556 -0.142361 -0.788194   \n",
      "4  Alif    0    0 -0.107527 -0.258065 -0.139785 -0.562724 -0.161290 -0.792115   \n",
      "\n",
      "        L5x  ...      L17x      L17y      L18x      L18y      L19x      L19y  \\\n",
      "0 -0.138686  ... -0.076642 -0.109489  0.200730  0.021898 -0.164234  0.054745   \n",
      "1 -0.139860  ... -0.132867 -0.143357  0.188811 -0.080420 -0.153846 -0.055944   \n",
      "2 -0.170909  ... -0.174545 -0.123636  0.203636 -0.036364 -0.138182  0.025455   \n",
      "3 -0.142361  ... -0.152778 -0.170139  0.218750 -0.121528 -0.093750 -0.100694   \n",
      "4 -0.161290  ... -0.154122 -0.150538  0.189964 -0.057348 -0.143369 -0.043011   \n",
      "\n",
      "       L20x      L20y      L21x      L21y  \n",
      "0 -0.164234  0.036496 -0.080292  0.014599  \n",
      "1 -0.192308 -0.055944 -0.160839 -0.076923  \n",
      "2 -0.203636  0.021818 -0.192727 -0.003636  \n",
      "3 -0.177083 -0.083333 -0.177083 -0.093750  \n",
      "4 -0.200717 -0.050179 -0.186380 -0.082437  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Splitting data\n",
      "Hidden layer size,trainDataAccuracy,testDataAccuracy\n",
      "Creating model\n",
      "Training....\n",
      "100, 0.9978539456741676 ,0.9941147621383031\n",
      "Model score on train data:  0.9978539456741676\n",
      "Model score on test data:  0.9941147621383031\n"
     ]
    }
   ],
   "source": [
    "#Two individuals\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Path to the dataset\n",
    "path = \"dataset/keypoint.csv\"\n",
    "\n",
    "# Reading dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Printing 1st 5 rows of the data set to ensure file and content loaded correctly\n",
    "print( df.head() )\n",
    "\n",
    "# Checking for empty parameters in records\n",
    "df.isna().any()\n",
    "\n",
    "# Separating column numbers from 1 to the last column as input for the MLP classifier\n",
    "X = df.iloc[:, 1:]\n",
    "\n",
    "#Separating 1st column as the output\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "# Splitting data in to training and testing\n",
    "print(\"Splitting data\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "print(\"Hidden layer size,trainDataAccuracy,testDataAccuracy\")\n",
    "\n",
    "# Making the MLP model\n",
    "print(\"Creating model\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "activation='logistic', solver='adam',\n",
    "learning_rate='constant', learning_rate_init=0.001,\n",
    "max_iter=5000)\n",
    "\n",
    "# Training the model on dataset\n",
    "print(\"Training....\")\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "#print(\"Training.... Done\")\n",
    "\n",
    "#print(\"Predicting\")\n",
    "# Testing the model using test data\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "# Printing model accuraccy on training dataset and testing dataset\n",
    "print(str(100)+\",\",str(model.score(X_train, y_train)),str(\",\")+str(model.score(X_test, y_test)))\n",
    "print(\"Model score on train data: \",model.score(X_train, y_train))\n",
    "print(\"Model score on test data: \",model.score(X_test, y_test))\n",
    "\n",
    "# Filename/Path for the model to be saved\n",
    "filename = 'models/finalized_model_meg_pank_keypoint.sav'\n",
    "\n",
    "# Saving model\n",
    "pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed10249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sign  L1x  L1y       L2x       L2y       L3x       L3y       L4x       L4y  \\\n",
      "0    1  0.0  0.0 -0.139535 -0.116279 -0.217054 -0.251938 -0.201550 -0.372093   \n",
      "1    1  0.0  0.0 -0.131783 -0.108527 -0.209302 -0.244186 -0.205426 -0.364341   \n",
      "2    1  0.0  0.0 -0.135659 -0.108527 -0.220930 -0.255814 -0.213178 -0.383721   \n",
      "3    1  0.0  0.0 -0.134100 -0.111111 -0.214559 -0.256705 -0.214559 -0.383142   \n",
      "4    1  0.0  0.0 -0.135659 -0.108527 -0.213178 -0.251938 -0.209302 -0.375969   \n",
      "\n",
      "        L5x  ...      L17x      L17y      L18x      L18y      L19x      L19y  \\\n",
      "0 -0.143411  ... -0.034884 -0.286822  0.201550 -0.341085  0.182171 -0.430233   \n",
      "1 -0.155039  ... -0.038760 -0.271318  0.201550 -0.333333  0.174419 -0.414729   \n",
      "2 -0.143411  ... -0.034884 -0.255814  0.193798 -0.337209  0.170543 -0.406977   \n",
      "3 -0.157088  ... -0.038314 -0.279693  0.199234 -0.340996  0.168582 -0.417625   \n",
      "4 -0.143411  ... -0.031008 -0.251938  0.213178 -0.329457  0.186047 -0.410853   \n",
      "\n",
      "       L20x      L20y      L21x      L21y  \n",
      "0  0.093023 -0.341085  0.042636 -0.275194  \n",
      "1  0.085271 -0.317829  0.034884 -0.244186  \n",
      "2  0.081395 -0.306202  0.031008 -0.236434  \n",
      "3  0.080460 -0.325670  0.042146 -0.260536  \n",
      "4  0.093023 -0.313953  0.046512 -0.248062  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "Splitting data\n",
      "Hidden layer size,trainDataAccuracy,testDataAccuracy\n",
      "Creating model\n",
      "Training....\n",
      "100, 0.9983251451540867 ,0.9976183387913069\n",
      "Model score on train data:  0.9983251451540867\n",
      "Model score on test data:  0.9976183387913069\n"
     ]
    }
   ],
   "source": [
    "#Two individuals\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Path to the dataset\n",
    "path = \"dataset/4_ind_hands.csv\"\n",
    "\n",
    "# Reading dataset\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Printing 1st 5 rows of the data set to ensure file and content loaded correctly\n",
    "print( df.head() )\n",
    "\n",
    "# Checking for empty parameters in records\n",
    "df.isna().any()\n",
    "\n",
    "# Separating column numbers from 1 to the last column as input for the MLP classifier\n",
    "X = df.iloc[:, 1:]\n",
    "\n",
    "#Separating 1st column as the output\n",
    "y = df.iloc[:, :1]\n",
    "\n",
    "# Splitting data in to training and testing\n",
    "print(\"Splitting data\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n",
    "\n",
    "print(\"Hidden layer size,trainDataAccuracy,testDataAccuracy\")\n",
    "\n",
    "# Making the MLP model\n",
    "print(\"Creating model\")\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,),\n",
    "activation='logistic', solver='adam',\n",
    "learning_rate='constant', learning_rate_init=0.001,\n",
    "max_iter=5000)\n",
    "\n",
    "# Training the model on dataset\n",
    "print(\"Training....\")\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "#print(\"Training.... Done\")\n",
    "\n",
    "#print(\"Predicting\")\n",
    "# Testing the model using test data\n",
    "#predictions = model.predict(X_test)\n",
    "\n",
    "# Printing model accuraccy on training dataset and testing dataset\n",
    "print(str(100)+\",\",str(model.score(X_train, y_train)),str(\",\")+str(model.score(X_test, y_test)))\n",
    "print(\"Model score on train data: \",model.score(X_train, y_train))\n",
    "print(\"Model score on test data: \",model.score(X_test, y_test))\n",
    "\n",
    "# Filename/Path for the model to be saved\n",
    "filename = 'models/finalized_model_4ind_keypoint.sav'\n",
    "\n",
    "# Saving model\n",
    "pickle.dump(model, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a25b4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
